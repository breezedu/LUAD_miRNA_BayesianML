trainData <- predict( trainData_range_model, newdata = x)
trainData$class <- y
head(trainData)
dim(x_test)
testData_range_model <- preProcess( x_test, method = c("center", "scale") )
testData <- predict( testData_range_model, newdata = x_test)
testData$class <- y_test
head(testData)
dim( trainData )
dim( testData )
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free"))
)
set.seed(100)
model_mars = train(class ~ .,
data=trainData,
method='earth'
#savePredictions = T
)
install.packages("e1071")
set.seed(100)
model_mars = train(class ~ .,
data=trainData,
method='earth'
#savePredictions = T
)
model_mars
fitted <- predict(model_mars)
plot(model_mars, main="Model Accuracies with MARS")
varimp_mars <- varImp(model_mars)
plot(varimp_mars, main="Variable Importance with MARS")
varimp_mars$importance
fitControl <- trainControl(
method = 'repeatedcv',           # k-fold cross validation
number = 15,                     # number of folds
repeats = 10,                    # number of repeats
savePredictions = T,             # saves predictions for optimal tuning parameter
classProbs = T,                  # should class probabilities be returned
summaryFunction=twoClassSummary  #,  # results summary function
# savePredictions = 'final'
)
set.seed(12345)
model_svmLinear = train(class ~ .,
data=trainData,
method='svmLinear',
tuneLength = 12,
metric='ROC',
trControl = fitControl
)
model_svmLinear = train(class ~ .,
data=trainData,
method='svmLinear',
tuneLength = 12,
metric='ROC',
trControl = fitControl
)
model_svmLinear
varimp_svmLinear <- varImp(model_svmLinear)
plot(varimp_svmLinear, main="Variable Importance with svmLinear")
rocobj_svmlinear <- roc(model_svmLinear$pred$obs, model_svmLinear$pred$tumor, ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="svmLinear",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=5,
print.auc=TRUE)
predicted2 <- predict(model_svmLinear, testData)
confusionMatrix(reference = testData$class, data = predicted2, mode='everything', positive='tumor')
path <- "C:/Users/dug/OneDrive - QIAGEN GmbH/SVM_RFE_Prj/0507CleanedData/Plots/"
path <- paste0(getwd(), "/Plots0703/" )
path
PlotROCSaveJPG(rocobj_svmlinear, path, "svmLinear_tune30_train70", "svmLinear" )
predicted2
marsGrid <-  expand.grid(nprune = c(1:10),
degree = c(1:3))
set.seed(123)
model_marsG = train(class ~ .,
data=trainData,
method='earth',
metric='ROC',
tuneGrid = marsGrid,
trControl = fitControl
)
set.seed(100)
model_rf = train(class ~ .,
data=trainData,
method='rf',
metric='ROC',
#tuneGrid = gbmGrid,
tuneLength = 20,
trControl = fitControl
)
set.seed(100)
model_svmRadial = train(class ~ .,
data=trainData,
method='svmRadial',
tuneLength=7,
trControl = fitControl
)
rocobj_svmRadial <- roc(model_svmRadial$pred$obs,
model_svmRadial$pred$tumor,
ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="svmRadial",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=4,
print.auc=TRUE)
PlotROCSaveJPG(rocobj_svmRadial, path, "svmRadical_tune5", "svmRadical" )
predict_svmRadical <- predict(model_svmRadial, testData)
confusionMatrix(reference = testData$class, data = predict_svmRadical, mode='everything', positive='tumor')
set.seed(100)
model_knn = train(class ~ .,
data=trainData,
method='knn',
tuneLength=4,
trControl = fitControl
)
model_knn$result
rocobj_knn <- roc(model_knn$pred$obs,
model_knn$pred$tumor,
ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="KNN",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=4,
print.auc=TRUE
)
predict_knn <- predict(model_knn, testData)
confusionMatrix(reference = testData$class, data = predict_knn, mode='everything', positive='tumor')
set.seed(100)
model_knn = train(class ~ .,
data=trainData,
method='knn',
tuneLength=8,
trControl = fitControl
)
model_knn$result
rocobj_knn <- roc(model_knn$pred$obs,
model_knn$pred$tumor,
ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="KNN",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=4,
print.auc=TRUE
)
predict_knn <- predict(model_knn, testData)
confusionMatrix(reference = testData$class, data = predict_knn, mode='everything', positive='tumor')
PlotROCSaveJPG(rocobj_knn, path, "KNN_tune4", "KNN" )
rocobj_ada <- roc(model_ada$pred$obs,
model_ada$pred$tumor,
ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="ADA",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=4,
print.auc=TRUE
)
model_ada = train(class ~ .,
data=trainData,
method='ada',
tuneLength=2,
trControl = fitControl
)
top.genes <- top.genes[1:18]
length(top.genes)
head(design)
head(count)
colnames(count)
rownames.ori <- rownames( count )
rownames.new <- make.names(rownames.ori, unique = T)
row.names(count) <- rownames.new
top.genes <- make.names(top.genes, unique = T)
top.genes
count[1:5, 1:5]
top.genes[1:10]
datamatrix <- count
length(top.genes)
constantRow <- row.names(as.matrix(which(apply(datamatrix, MARGIN = 1, function(x) var(x) < 0.0001) ) ) )
constantRow <- NULL
dim(datamatrix)
count <- datamatrix[!row.names(datamatrix) %in% constantRow,]
count <- datamatrix[ row.names(datamatrix) %in% top.genes, ]
print("These variables get constant values, thus got droped during PCA scale:")
constantRow
my_data <- as.data.frame( t(count) )
dim(count)
my_data$class <- design$SampleType
summary(my_data$class)
my_data$class <- ifelse(my_data$class=="Solid Tissue Normal", "normal", "tumor")
dim(my_data)
my_data[1:5, 1:5]
summary(my_data$class)
my_data$class <- factor(my_data$class)
summary(my_data$class)
set.seed(1234)
trainRowNumbers <- createDataPartition(my_data$class, p=0.70, list=FALSE)
trainData <- my_data[trainRowNumbers,]
testData <- my_data[-trainRowNumbers,]
dim(trainData)
dim(testData)
col.len <- dim(trainData)[2]
col.len
x = trainData[, 1:col.len-1]
y = trainData$class
x_test = testData[ , 1:col.len-1]
y_test = testData$class
dim(x)
dim(x_test)
x$class
x <- x[,apply(x, 2, var, na.rm=TRUE) > 0.0001]
dim(x)
trainData_range_model <- preProcess( x, method = c("center", "scale") )
trainData <- predict( trainData_range_model, newdata = x)
trainData$class <- y
head(trainData)
dim(x_test)
testData_range_model <- preProcess( x_test, method = c("center", "scale") )
testData$class <- y_test
testData <- predict( testData_range_model, newdata = x_test)
head(testData)
dim( trainData )
dim( testData )
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free"))
)
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
set.seed(1234)
options(warn=-1)
subsets <- c(1:45)
dim(trainData)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",      ## cross-validation
number = 10,                ## fold of cross validation
repeats = 3,                ## repeats of cv
verbose = FALSE
)
lmProfile <- rfe(x=trainData[, 1:45],
y=trainData$class,
sizes = subsets,        ## model sizes (the number of most important genes to choose)
rfeControl = ctrl       ## use rfeControl output as reference: algorithm and cv to use;
)
fitControl <- trainControl(
method = 'repeatedcv',           # k-fold cross validation
number = 15,                     # number of folds
repeats = 10,                    # number of repeats
savePredictions = T,             # saves predictions for optimal tuning parameter
classProbs = T,                  # should class probabilities be returned
summaryFunction=twoClassSummary  #,  # results summary function
# savePredictions = 'final'
)
set.seed(12345)
model_svmLinear = train(class ~ .,
data=trainData,
method='svmLinear',
tuneLength = 12,
metric='ROC',
trControl = fitControl
)
model_svmLinear
varimp_svmLinear <- varImp(model_svmLinear)
plot(varimp_svmLinear, main="Variable Importance with svmLinear")
rocobj_svmlinear <- roc(model_svmLinear$pred$obs, model_svmLinear$pred$tumor, ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="svmLinear",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=5,
print.auc=TRUE)
predicted2 <- predict(model_svmLinear, testData)
confusionMatrix(reference = testData$class, data = predicted2, mode='everything', positive='tumor')
predicted2 <- predict(model_svmLinear, testData)
confusionMatrix(reference = testData$class, data = predicted2, mode='everything', positive='tumor')
dim(testData)
dim(trainData)
setwd("C:/Users/Jeff/OneDrive - QIAGEN GmbH/SVM_RFE_Prj/Jeff_Shuai/RCode/")
count <- read.table("LUAD_plus_LUSCNormal.MirnaSeq_Count.txt", row.names = 1, header = T, sep = "\t")
design <- read.table("LUAD_plus_LUSCNormal.MirnaSeq_Count_Design.txt", row.names = 1, header = T, sep = "\t")
top.genes <- readLines("DESeq2_compare2Normal_topGeneList.txt")
top.genes <- top.genes[1:18]
length(top.genes)
head(design)
head(count)
colnames(count)
rownames.ori <- rownames( count )
rownames.new <- make.names(rownames.ori, unique = T)
row.names(count) <- rownames.new
top.genes <- make.names(top.genes, unique = T)
top.genes
count[1:5, 1:5]
top.genes[1:10]
length(top.genes)
datamatrix <- count
dim(datamatrix)
constantRow <- row.names(as.matrix(which(apply(datamatrix, MARGIN = 1, function(x) var(x) < 0.0001) ) ) )
constantRow <- NULL
count <- datamatrix[!row.names(datamatrix) %in% constantRow,]
count <- datamatrix[ row.names(datamatrix) %in% top.genes, ]
print("These variables get constant values, thus got droped during PCA scale:")
constantRow
my_data <- as.data.frame( t(count) )
dim(count)
dim(my_data)
my_data$class <- design$SampleType
summary(my_data$class)
my_data$class <- ifelse(my_data$class=="Solid Tissue Normal", "normal", "tumor")
summary(my_data$class)
my_data[1:5, 1:5]
my_data$class <- factor(my_data$class)
summary(my_data$class)
set.seed(1234)
trainRowNumbers <- createDataPartition(my_data$class, p=0.70, list=FALSE)
trainData <- my_data[trainRowNumbers,]
testData <- my_data[-trainRowNumbers,]
dim(trainData)
dim(testData)
col.len <- dim(trainData)[2]
col.len
x = trainData[, 1:col.len-1]
y = trainData$class
x_test = testData[ , 1:col.len-1]
y_test = testData$class
dim(x)
dim(x_test)
x$class
x <- x[,apply(x, 2, var, na.rm=TRUE) > 0.0001]
dim(x)
trainData_range_model <- preProcess( x, method = c("center", "scale") )
trainData <- predict( trainData_range_model, newdata = x)
trainData$class <- y
head(trainData)
dim(x_test)
testData_range_model <- preProcess( x_test, method = c("center", "scale") )
testData <- predict( testData_range_model, newdata = x_test)
testData$class <- y_test
head(testData)
dim( trainData )
dim( testData )
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free"))
)
fitControl <- trainControl(
method = 'repeatedcv',           # k-fold cross validation
number = 15,                     # number of folds
repeats = 10,                    # number of repeats
savePredictions = T,             # saves predictions for optimal tuning parameter
classProbs = T,                  # should class probabilities be returned
summaryFunction=twoClassSummary  #,  # results summary function
# savePredictions = 'final'
)
set.seed(12345)
model_svmLinear = train(class ~ .,
data=trainData,
method='svmLinear',
tuneLength = 12,
metric='ROC',
trControl = fitControl
)
model_svmLinear
varimp_svmLinear <- varImp(model_svmLinear)
plot(varimp_svmLinear, main="Variable Importance with svmLinear")
rocobj_svmlinear <- roc(model_svmLinear$pred$obs, model_svmLinear$pred$tumor, ci=TRUE,
plot=TRUE,
legacy.axes=TRUE, percent=TRUE,
main="svmLinear",
xlab="False Positive Percentage",
ylab="True Postive Percentage",
col="darkblue", lwd=5,
print.auc=TRUE)
predicted2 <- predict(model_svmLinear, testData)
confusionMatrix(reference = testData$class, data = predicted2, mode='everything', positive='tumor')
top.genes <- readLines("DESeq2_compare2Normal_topGeneList.txt")
top.genes <- top.genes[1:50]
length(top.genes)
head(design)
head(count)
colnames(count)
rownames.ori <- rownames( count )
rownames.new <- make.names(rownames.ori, unique = T)
row.names(count) <- rownames.new
top.genes <- make.names(top.genes, unique = T)
top.genes
count[1:5, 1:5]
top.genes[1:10]
length(top.genes)
datamatrix <- count
dim(datamatrix)
constantRow <- row.names(as.matrix(which(apply(datamatrix, MARGIN = 1, function(x) var(x) < 0.0001) ) ) )
constantRow <- NULL
count <- datamatrix[!row.names(datamatrix) %in% constantRow,]
count <- datamatrix[ row.names(datamatrix) %in% top.genes, ]
print("These variables get constant values, thus got droped during PCA scale:")
constantRow
my_data <- as.data.frame( t(count) )
dim(count)
dim(my_data)
my_data$class <- design$SampleType
summary(my_data$class)
my_data$class <- ifelse(my_data$class=="Solid Tissue Normal", "normal", "tumor")
summary(my_data$class)
my_data[1:5, 1:5]
my_data$class <- factor(my_data$class)
summary(my_data$class)
set.seed(1234)
trainRowNumbers <- createDataPartition(my_data$class, p=0.70, list=FALSE)
trainData <- my_data[trainRowNumbers,]
testData <- my_data[-trainRowNumbers,]
dim(trainData)
count <- read.table("LUAD_plus_LUSCNormal.MirnaSeq_Count.txt", row.names = 1, header = T, sep = "\t")
design <- read.table("LUAD_plus_LUSCNormal.MirnaSeq_Count_Design.txt", row.names = 1, header = T, sep = "\t")
top.genes <- readLines("DESeq2_compare2Normal_topGeneList.txt")
top.genes <- top.genes[1:50]
length(top.genes)
head(design)
head(count)
colnames(count)
rownames.ori <- rownames( count )
rownames.new <- make.names(rownames.ori, unique = T)
top.genes <- make.names(top.genes, unique = T)
top.genes
count[1:5, 1:5]
top.genes[1:10]
length(top.genes)
row.names(count) <- rownames.new
datamatrix <- count
dim(datamatrix)
constantRow <- row.names(as.matrix(which(apply(datamatrix, MARGIN = 1, function(x) var(x) < 0.0001) ) ) )
constantRow <- NULL
count <- datamatrix[!row.names(datamatrix) %in% constantRow,]
print("These variables get constant values, thus got droped during PCA scale:")
constantRow
my_data <- as.data.frame( t(count) )
dim(count)
dim(my_data)
my_data$class <- design$SampleType
summary(my_data$class)
my_data$class <- ifelse(my_data$class=="Solid Tissue Normal", "normal", "tumor")
summary(my_data$class)
my_data$class <- factor(my_data$class)
summary(my_data$class)
my_data[1:5, 1:5]
count <- datamatrix[ row.names(datamatrix) %in% top.genes, ]
set.seed(1234)
trainRowNumbers <- createDataPartition(my_data$class, p=0.70, list=FALSE)
trainData <- my_data[trainRowNumbers,]
dim(trainData)
testData <- my_data[-trainRowNumbers,]
dim(testData)
col.len <- dim(trainData)[2]
col.len
y = trainData$class
x = trainData[, 1:col.len-1]
x_test = testData[ , 1:col.len-1]
y_test = testData$class
dim(x)
dim(x_test)
x$class
x <- x[,apply(x, 2, var, na.rm=TRUE) > 0.0001]
dim(x)
trainData_range_model <- preProcess( x, method = c("center", "scale") )
trainData <- predict( trainData_range_model, newdata = x)
trainData$class <- y
head(trainData)
dim(x_test)
testData_range_model <- preProcess( x_test, method = c("center", "scale") )
testData <- predict( testData_range_model, newdata = x_test)
testData$class <- y_test
head(testData)
dim( trainData )
dim( testData )
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free"))
)
featurePlot(x = trainData[, 1:15],
y = trainData$class,
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
dim( trainData )
dim( testData )
